{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(\"housing_prices.csv\")\n",
    "print(df.head())  # Check the first few rows\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = df[['AREA', 'FLOOR', 'ROOM']].values  # Features\n",
    "y = df['PRICE'].values  # Target\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=100)\n",
    "\n",
    "# Create and train the linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Display model's intercept and coefficients\n",
    "print(\"Intercept (b0):\", model.intercept_)\n",
    "print(\"Coefficients (b1, b2, b3):\", model.coef_)\n",
    "\n",
    "# Evaluate the model's R² score on both train and test data\n",
    "train_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "\n",
    "print(\"R² Train Score:\", train_score)\n",
    "print(\"R² Test Score:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('student.csv')\n",
    "\n",
    "# Extract values\n",
    "math = data['Math'].values\n",
    "read = data['Reading'].values\n",
    "write = data['Writing'].values\n",
    "\n",
    "# Prepare data for gradient descent\n",
    "m = len(math)\n",
    "x0 = np.ones(m)\n",
    "X = np.array([x0, math, read]).T  # Feature matrix (intercept + math + reading scores)\n",
    "\n",
    "# Initialize coefficients\n",
    "B = np.array([0, 0, 0])\n",
    "\n",
    "# Cost function (Mean Squared Error)\n",
    "def cost_function(X, Y, B):\n",
    "    m = len(Y)\n",
    "    J = np.sum((X.dot(B) - Y) ** 2) / (2 * m)\n",
    "    return J\n",
    "\n",
    "# Gradient descent to find the best coefficients\n",
    "def gradient_descent(X, Y, B, alpha, iterations):\n",
    "    cost_history = [0] * iterations\n",
    "    m = len(Y)\n",
    "    for iteration in range(iterations):\n",
    "        h = X.dot(B)  # Predicted values\n",
    "        loss = h - Y\n",
    "        gradient = X.T.dot(loss) / m\n",
    "        B = B - alpha * gradient\n",
    "        cost_history[iteration] = cost_function(X, Y, B)\n",
    "    return B, cost_history\n",
    "\n",
    "# Run Gradient Descent\n",
    "B, cost_history = gradient_descent(X, write, B, alpha=0.0001, iterations=100000)\n",
    "\n",
    "# Print the results\n",
    "print(\"Optimized Coefficients (B):\", B)\n",
    "print(\"Final Cost after Gradient Descent:\", cost_history[-1])\n",
    "\n",
    "# Evaluate the model using R2 score\n",
    "def r2_score(Y, Y_pred):\n",
    "    ss_tot = np.sum((Y - np.mean(Y)) ** 2)\n",
    "    ss_res = np.sum((Y - Y_pred) ** 2)\n",
    "    return 1 - (ss_res / ss_tot)\n",
    "\n",
    "Y_pred = X.dot(B)\n",
    "print(\"R2 Score:\", r2_score(write, Y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
